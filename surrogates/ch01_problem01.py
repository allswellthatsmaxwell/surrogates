# AUTOGENERATED! DO NOT EDIT! File to edit: ch01_problem01.ipynb (unless otherwise specified).

__all__ = ['length', 'DataManager', 'attach_std', 'plot_scatter', 'plot_predictions_actual',
           'plot_predictions_residuals', 'plot_predictions', 'wires_facet_theme']

# Cell
#export
from nbdev.showdoc import *
import pandas as pd
import numpy as np
import plotnine as pn
from typing import List
from sklearn.linear_model import LinearRegression

# Cell

def length(x: pd.Series):
    return np.sqrt(np.sum(np.square(x)))


class DataManager:
    def __init__(self, data: pd.DataFrame = None, response="pstren",
                 datafile="http://bobby.gramacy.com/surrogates/wire.csv"):
        self.data = data
        if self.data is None:
            self.data = pd.read_csv(datafile)
        self.data.columns = [s.strip() for s in self.data.columns]
        self.response: str = response
        self.predictors: List[str] = self._get_predictors()
        self.normalized = False
        self.hypercubed = False
        self.orig_lengths = {}


    def spawn(self, new_data: pd.DataFrame):
        new = DataManager(data=new_data.copy(), response=self.response)
        new.orig_mean = self.orig_mean
        new.orig_std  = self.orig_std
        new.orig_lengths = self.orig_lengths.copy()
        return new


    def _get_predictors(self) -> List[str]:
        return [colname for colname in self.data.columns if colname != self.response]


    def predictors_to_hypercube(self):
        """ Scales each predictor to length 1. """
        if self.hypercubed:
            raise AssertionError("Predictors already scaled to hypercube.")
        for colname in self.predictors:
            try:
                # Use the original if it exists.
                # Useful for spawned managers - they'll use the
                # parent original lengths.
                orig_length = self.orig_lengths[colname]
            except KeyError:
                orig_length = length(self.data[colname])
            self.orig_lengths[colname] = orig_length
            self.data[colname] /= orig_length
        self.hypercubed = True


    def normalize_response(self):
        """
        Scales the response to a mean of 0 and standard deviation of 1.
        """
        if self.normalized:
            raise AssertionError("Response already scaled to (mean, std) = (0, 1).")
        self.orig_mean = np.mean(self.data[self.response])
        self.orig_std = np.std(self.data[self.response])
        self.data[self.response] -= self.orig_mean
        self.data[self.response] /= self.orig_std
        self.normalized = True


    def unscale_prediction(self, pred: float):
        return pred * self.orig_std + self.orig_mean



    def make_quadratic_variables_wide(self) -> pd.DataFrame:
        """
        Returns a matrix with one column per variable combination, i.e.
        all the cross-multiplications. Also with one column per original variable.
        """
        interactions = {}
        for i, coli in enumerate(self.predictors):
            interactions[coli] = self.data[coli]
            for j in range(i, len(self.predictors)):
                colj = self.predictors[j]
                interactions[f"{coli}*{colj}"] = self.data[coli] * self.data[colj]
        return pd.DataFrame(interactions)


    def make_quadratic_variables_long(self, wide=None):
        if wide is None:
            wide = self.make_quadratic_variables_wide()
        dfs = []
        idx = range(wide.shape[0])
        for colname in wide.columns:
            df = pd.DataFrame({'val': wide[colname]})
            df['var'] = colname
            df['response'] = self.data[self.response]
            dfs.append(df)
        return pd.concat(dfs)[['var', 'val', 'response']]


    def make_grid(self, x1_name, x2_name) -> pd.DataFrame:
        """
        Makes a dataframe with the columns (var, x1, x2, self.response),
        where var is some string variable combination (e.g. s * t), x1 is the value
        of s, x2 is the value of t, and self.response is the value of the response
        at that actual s, t combination in the data.
        """
        df = self.data[[x1_name, x2_name, self.response]]
        df.columns = ['x1', 'x2', self.response]

        df['var'] = f"{x1_name}*{x2_name}"
        return df.drop_duplicates()


    def make_grids(self) -> pd.DataFrame:
        """
        Applies make_grid for every variable combination in the data.
        """
        dfs = []
        icols = self.predictors
        for i in range(len(self.predictors)):
            dfs.append(self.make_grid(self.predictors[i], self.predictors[i]))
            for j in range(i - 1, len(self.predictors)):
                df = self.make_grid(self.predictors[i], self.predictors[j])
                dfs.append(df)
        return pd.concat(dfs)


    def get_linear_slopes(self, grids_df):
        """
        Returns a dataframe with each variable in grids_df, and the size
        of each linear slope when a predictor on only that variable
        is fit to this manager's data.
        """
        slope_rows = []
        for name, df in grids_df.groupby('var'):
            model = LinearRegression()
            X = pd.DataFrame(df['x1'] * df['x2']).values
            y = df[self.response].values
            model.fit(X, y)
            assert len(model.coef_) == 1
            slope = model.coef_[0]
            row = (name, slope)
            slope_rows.append(row)

        for name in self.predictors:
            df = grids_df[grids_df['var'] == f"{name}*{name}"]
            df = df.iloc[0:self.data.shape[0], :]

            if df.shape[0] != self.data.shape[0]:
                print(df)
                raise AssertionError(f"got {df.shape[0]} rows but expected {self.data.shape[0]}")
            X, y = pd.DataFrame(df['x1']).values, df[self.response].values
            model = LinearRegression().fit(X, y)
            assert len(model.coef_) == 1
            slope_rows.append((name, model.coef_[0]))
        slopes_df = pd.DataFrame(slope_rows, columns=['var', 'slope'])
        slopes_df['abs_slope'] = slopes_df['slope'].abs()
        return slopes_df.sort_values('abs_slope', ascending=False)


wires_facet_theme = pn.theme(
    subplots_adjust={'hspace': 0.25},
    figure_size=(18, 15))


def attach_std(pred_df: pd.DataFrame, variance: np.array) -> None:
    pred_df['lb'] = pred_df['pred'] - np.sqrt(variance)
    pred_df['ub'] = pred_df['pred'] + np.sqrt(variance)


def plot_scatter(dat, figsize=(16, 12)):
    return (
        pn.ggplot(dat, pn.aes(x='val', y='response')) +
        pn.geom_point() +
        pn.geom_smooth(method='lm') +
        pn.facet_wrap("var", scales='free_x') +
        pn.theme_bw() +
        pn.theme(figure_size=figsize, subplots_adjust={'hspace': 0.25}))


def plot_predictions_actual(pred_df, figsize):
    return (
        pn.ggplot(pred_df, pn.aes(x='y', y='pred')) +
        pn.geom_point() +
        pn.geom_ribbon(pn.aes(ymin='lb', ymax='ub'), alpha=0.3) +
        pn.geom_abline(slope=1, intercept=0) +
        pn.theme_bw() +
        pn.theme(figure_size=figsize))


def plot_predictions_residuals(pred_df, figsize):
    return (
        pn.ggplot(pred_df, pn.aes(x='y', y='resid')) +
        pn.geom_point() +
        pn.geom_hline(yintercept=0) +
        pn.theme_bw() +
        pn.theme(figure_size=figsize))


def plot_predictions(pred_df, figsize):
    actual = plot_predictions_actual(pred_df, figsize) + pn.ggtitle('actuals')
    display(actual);
    resid = plot_predictions_residuals(pred_df, figsize) + pn.ggtitle('residuals')
    display(resid);